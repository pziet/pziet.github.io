<!DOCTYPE html>
<html>

<head>
  <link rel="stylesheet" href="styles.css">
  <title>Vita</title>
  <script src="script.js"></script>
</head>
<div id="menu-placeholder"></div>
<div class="content">

  <body>
    <h2>Vita</h2>
    <p>Last updated: 09/09/2024</p>

    <p><strong>Summary</strong>: Looking for engineering roles in AI. I have a strong foundation in mathematics coupled
      with advanced programming ability. This enables me to quickly iterate on and implement complex ideas. I am
      naturally optimistic, an effective team player, a quick learner, and possess high stamina. <br><br>Here is some
      illustrative work, see my <a href="https://github.com/pziet" target="_blank">GitHub</a> and <a
        href="https://pziet.github.io/projects.html" target="_blank">website</a> for more.</p>
    <ol>
      <li><strong>Eval Framework</strong>: Developed LLM testing infrastructure for <a href="https://www.sea.dev/">sea.dev</a>. The
        evals test the ability of LLMs to extract information from multi-turn dialogue, implementing recursive prompt
        architectures to measure information extraction accuracy across conversation depths.</li>
      <li><strong>Sherlock Holmes Eval</strong> (<a href="https://youtu.be/d7ZL-05tsq0" target="_blank">video</a>/<a
          href="https://github.com/pziet/sherlock" target="_blank">repo</a>): Test a LLM's ability to identify
        the culprit in murder mysteries.</li>
      <li><strong>Guaranteeing JSON from GPT-2</strong> (<a href="https://youtu.be/HX5BCtUexo8?si=yj9mrwVfypco9dPI"
          target="_blank">video</a>/<a href="https://github.com/pziet/build-nanogpt/tree/master"
          target="_blank">repo</a>): Reproduced GPT-2 on 8xA100 GPUs, fixed a subset of tokens in the output sequence to
        be JSON schema leaving gaps for model to generate the values.</li>
      <li><strong>Training algorithm for regularized models on arbitrarily large data sets</strong> (<a
          href="https://youtu.be/0mtZqF1rxdg" target="_blank">video</a>/<a href="https://arxiv.org/pdf/2307.07342"
          target="_blank">arXiv</a>/<a href="https://github.com/ikosmidis/bigbr-supplementary-material"
          target="_blank">repo</a>): Eliminates requirement of storing <em>O(n)</em> quantities in memory, and allows
        for training data to be stored in distinct sites for privacy concerns.</li>
      <li><strong>Debiased high-dimensional logistic regression</strong> (<a href="https://youtu.be/CjdIkAm1aFM"
          target="_blank">video</a>/<a href="https://arxiv.org/pdf/2311.11290" target="_blank">arXiv</a>/<a
          href="https://github.com/ikosmidis/mJPL-conjecture-supplementary" target="_blank">repo</a>): Conjecture to
        debias model in setting where both the number of features and observations are asymptotically increasing.</li>
    </ol>
    <h3>Technical Skills</h3>
    <ul>
      <li><strong>Languages:</strong> Python, R, JavaScript, SQL</li>
      <li><strong>Packages, Frameworks:</strong> PyTorch, CUDA, HPC clusters, React, Django, AWS </li>
      <li><strong>Expertise:</strong> numerical optimization, computational linear algebra, and ML theory (transformers,
        stochastic gradient descent, deep learning, Markov processes)</li>
    </ul>
    <h3>Education</h3>
    <p>
      <strong>PhD in Mathematical Statistics.</strong> <a href="https://warwick.ac.uk/"><i>University of
          Warwick</i></a>.
      Oct 2020 - Aug 2024.<br>Supervisor: <a href="https://www.ikosmidis.com/" target="_blank">Prof. Ioannis
        Kosmidis</a><br>Publications: On <a href="https://arxiv.org/pdf/2307.07342" target="_blank">fitting models to
        very
        large data sets</a> and <a href="https://arxiv.org/pdf/2311.11290" target="_blank">debiasing high-dimensional
        logistic regression</a>, see my <a href="https://scholar.google.com/citations?hl=en&user=IyiPlGgAAAAJ"
        target="_blank">Google Scholar</a>.
    </p>
    <p>
      <strong>MSc in Statistics.</strong> <a href="https://warwick.ac.uk/"><i>University of Warwick</i></a>. Oct 2019 -
      Sep 2020.<br>Dissertation: Bias-reduced logistic regression in high
      dimensions and model estimation with arbitrarily large <i>n</i>.<br>Awards: <a
        href="https://warwick.ac.uk/fac/sci/statistics/postgrad/gradstudentprizes/" target="_blank">Winton Award</a>
      (Finished 1st in class)
    </p>
    <p>
      <strong>BCom Actuarial Science with Honours in Statistics.</strong> <a href="https://www.uct.ac.za/"
        target="_blank"><i>University of Cape Town</i></a>. Feb 2015 - Nov 2018.<br>Awards: STA4006W Class Medal
      (Finished 1st in class), Commerce Faculty Scholarship, Dean's Merit List.
    </p>
    <h3>Experience</h3>
    <p>
      <strong>LLM Engineer.</strong> <a href="https://www.sea.dev/" target="_blank"><i>sea.dev</i></a>.
      Nov 2024.<br>Built multi-turn dialogue evaluation framework measuring LLM extraction accuracy.
    </p>
    <p>
      <strong>Data Scientist.</strong> <a href="https://www.linkedin.com/company/barrows/" target="_blank"><i>Barrows
          Global</i></a>.
      May 2019 - Aug 2019.<br>Cleaned and extracted features from major retailer's data, built models to analyse and
      draw inference on the sales performance in the store environment to inform the advertising strategy for
      clients.
    </p>
    <p>
      <strong>Actuarial Intern.</strong> <a href="https://www.oldmutual.com/" target="_blank"><i>Old Mutual
          Limited</i></a>. Feb
      2017.<br>Performed Value at Risk (VaR) modelling and worked with the reinsurance team to rectify a database
      error which produced duplicate policy holders.
    </p>
  </body>
</div>

</html>